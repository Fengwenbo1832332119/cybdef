# scripts/agent/eval_ppo_cskg_compare.py
# -*- coding: utf-8 -*-
"""
å¯¹æ¯”è¯„ä¼°å¤šä¸ª PPO+CSKG checkpointï¼š
- åŒä¸€å¥—ç¯å¢ƒ CybORGWrapper
- åŒä¸€å¥— CSKGï¼ˆcskg.yamlï¼‰
- å¯¹æ¯ä¸ª ckptï¼š
    1) å¸¦ CSKGï¼ˆcskgï¼‰
    2) å…³é—­ CSKGï¼ˆplainï¼‰
  åˆ†åˆ«è·‘è‹¥å¹² episodeï¼Œç»Ÿè®¡ï¼š
    - å¹³å‡ EnvReward Â± std
    - å¹³å‡æ­¥é•¿
    - åŠ¨ä½œä½¿ç”¨ Top-K

æ–°å¢ï¼š
- æŠŠæ‰€æœ‰ ckpt çš„è¯„ä¼°ç»“æœæ±‡æ€»åˆ°ä¸€å¼ è¡¨ï¼ˆç»ˆç«¯æ‰“å°å¯¹æ¯”çŸ©é˜µï¼‰
- åŒæ—¶å¯¼å‡ºåˆ° CSV æ–‡ä»¶ï¼Œä¾¿äºåç»­ç”»å›¾åˆ†æ
"""

import os
import sys
import time
import json
import pathlib
import argparse
import csv
from collections import Counter
from typing import Dict, Any

import numpy as np
import torch
import torch.nn as nn
from torch.distributions import Categorical

# ===== è·¯å¾„æ³¨å…¥ =====
ROOT = pathlib.Path(__file__).resolve().parents[2]  # C:\cybdef
THIRD = ROOT / "third_party" / "CybORG"

for p in (ROOT, THIRD):
    if str(p) not in sys.path:
        sys.path.insert(0, str(p))

# ===== é¡¹ç›®å†… import =====
from scripts.envs.cyborg_wrapper import CybORGWrapper
from scripts.cskg.reasoner import KnowledgeBridge
import yaml

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ===== å’Œ train_ppo_cskg.py å®Œå…¨ä¸€è‡´çš„ç½‘ç»œç»“æ„ =====
class ActorCritic(nn.Module):
    def __init__(self, obs_dim: int, act_dim: int, hidden=128):
        super().__init__()
        self.actor = nn.Sequential(
            nn.Linear(obs_dim, hidden),
            nn.Tanh(),
            nn.Linear(hidden, hidden),
            nn.Tanh(),
            nn.Linear(hidden, act_dim),
        )
        self.critic = nn.Sequential(
            nn.Linear(obs_dim, hidden),
            nn.Tanh(),
            nn.Linear(hidden, hidden),
            nn.Tanh(),
            nn.Linear(hidden, 1),
        )

    def forward(self, obs):
        logits = self.actor(obs)
        value = self.critic(obs)
        return logits, value.squeeze(-1)


def to_obs_vector(obs_raw: Any) -> np.ndarray:
    """
    å…¼å®¹ CybORGWrapper.reset()/step() è¿”å›çš„ dict ç»“æ„ï¼š
    - {"obs_vec": np.ndarray, "facts": {...}, "raw": ...}
    """
    if isinstance(obs_raw, dict):
        if "obs_vec" in obs_raw:
            arr = obs_raw["obs_vec"]
        else:
            for k in ["obs", "observation", "vector", "state"]:
                if k in obs_raw:
                    arr = obs_raw[k]
                    break
            else:
                raise TypeError(f"obs_raw ä¸­æ‰¾ä¸åˆ° obs_vec/obs ç­‰å­—æ®µ: keys={list(obs_raw.keys())}")
    else:
        arr = obs_raw

    arr = np.array(arr, dtype=np.float32).reshape(-1)
    return arr


def load_ppo_config() -> Dict[str, Any]:
    """ä» scripts/configs/ppo.yaml è¯»å– rule_coef ç­‰å‚æ•°ï¼Œæ²¡æœ‰å°±ç”¨é»˜è®¤"""
    ppo_yaml = ROOT / "scripts" / "configs" / "ppo.yaml"
    if not ppo_yaml.exists():
        print(f"âš  æœªæ‰¾åˆ° {ppo_yaml}ï¼Œä½¿ç”¨ rule_coef=0.1, device=cuda/cpu è‡ªåŠ¨")
        return {
            "rule_coef": 0.1,
            "device": "cuda" if torch.cuda.is_available() else "cpu",
        }
    with open(ppo_yaml, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f) or {}
    return cfg


def build_env() -> CybORGWrapper:
    env_yaml = ROOT / "scripts" / "configs" / "env.yaml"
    env = CybORGWrapper(str(env_yaml))
    return env


def build_kb() -> KnowledgeBridge:
    cskg_yaml = ROOT / "scripts" / "configs" / "cskg.yaml"
    seed_graph = ROOT / "scripts" / "configs" / "seed_graph.json"
    kb = KnowledgeBridge(
        seed_graph_path=str(seed_graph),
        cskg_rules_path=str(cskg_yaml),
        recent_steps=10,
    )
    return kb


def load_actor_critic(env: CybORGWrapper, ckpt_path: str) -> ActorCritic:
    obs_dim = env.obs_dim
    act_dim = env.action_dim
    ac = ActorCritic(obs_dim, act_dim)
    ckpt = torch.load(ckpt_path, map_location="cpu")
    state_dict = ckpt.get("model", ckpt)
    ac.load_state_dict(state_dict)
    ac.to(DEVICE)
    ac.eval()
    return ac


@torch.no_grad()
def run_episodes(
    env: CybORGWrapper,
    ac: ActorCritic,
    episodes: int = 20,
    use_cskg: bool = True,
    rule_coef: float = 0.1
) -> Dict[str, Any]:
    """
    ç”¨åŒä¸€ç½‘ç»œã€åŒä¸€ç¯å¢ƒè·‘è‹¥å¹²å›åˆï¼š
    - use_cskg=True  : å¸¦ CSKGï¼ˆprior + æ©ç ï¼‰
    - use_cskg=False : å…³é—­ CSKGï¼Œåªç”¨ env.legal_mask
    """
    action_names = env.action_space.names
    act_dim = env.action_dim

    kb = build_kb() if use_cskg else None

    ep_rewards = []
    ep_steps = []
    action_counter = Counter()

    for ep in range(1, episodes + 1):
        obs_raw = env.reset()
        obs_vec = to_obs_vector(obs_raw)
        facts = obs_raw.get("facts", {}) if isinstance(obs_raw, dict) else {}

        if kb is not None and hasattr(kb, "reset_episode"):
            kb.reset_episode()

        done = False
        total_r_env = 0.0
        step_count = 0

        while not done:
            step_count += 1

            obs_tensor = torch.from_numpy(obs_vec).to(DEVICE).unsqueeze(0)
            logits, _ = ac(obs_tensor)
            logits = logits.squeeze(0)  # [act_dim]

            # === å–åˆæ³•æ©ç  ===
            try:
                legal_mask_np = env._current_legal_mask().astype(np.float32)
            except Exception:
                legal_mask_np = np.ones(act_dim, dtype=np.float32)

            if legal_mask_np.shape[0] != act_dim:
                raise ValueError(f"legal_mask ç»´åº¦å¼‚å¸¸: {legal_mask_np.shape[0]} vs act_dim={act_dim}")

            # === CSKG åˆ†æ”¯ ===
            if use_cskg and kb is not None:
                # ç”¨ facts æ›´æ–° KB
                if hasattr(kb, "update_from_facts"):
                    kb.update_from_facts(facts)

                # prior logits
                prior_np = kb.prior_logits(facts, action_names)
                if isinstance(prior_np, tuple):
                    prior_np = prior_np[0]
                prior_np = np.array(prior_np, dtype=np.float32)

                # rule mask
                mask_res = kb.query_action_mask(facts, action_names)
                if isinstance(mask_res, tuple):
                    rule_mask_np = np.array(mask_res[0], dtype=np.float32)
                else:
                    rule_mask_np = np.array(mask_res, dtype=np.float32)

                if rule_mask_np.shape[0] != act_dim:
                    raise ValueError(f"rule_mask ç»´åº¦å¼‚å¸¸: {rule_mask_np.shape[0]} vs act_dim={act_dim}")
                if prior_np.shape[0] != act_dim:
                    raise ValueError(f"prior ç»´åº¦å¼‚å¸¸: {prior_np.shape[0]} vs act_dim={act_dim}")

                combined_mask_np = (legal_mask_np * rule_mask_np).astype(np.float32)
                if combined_mask_np.sum() <= 0:
                    combined_mask_np[0] = 1.0

                prior_t = torch.from_numpy(prior_np).to(DEVICE)
                logits = logits.clone()
                if rule_coef != 0.0:
                    logits = logits + rule_coef * prior_t
                else:
                    logits = logits + prior_t

                mask_t = torch.from_numpy(combined_mask_np).to(DEVICE)
                logits[mask_t == 0] = -1e9

            else:
                # ä¸ç”¨ CSKGï¼Œåªç”¨ç¯å¢ƒåˆæ³•åŠ¨ä½œ
                combined_mask_np = legal_mask_np
                if combined_mask_np.sum() <= 0:
                    combined_mask_np[0] = 1.0
                logits = logits.clone()
                mask_t = torch.from_numpy(combined_mask_np).to(DEVICE)
                logits[mask_t == 0] = -1e9

            dist = Categorical(logits=logits)
            action = dist.sample()
            a_idx = int(action.item())
            a_name = action_names[a_idx]
            action_counter[a_name] += 1

            next_obs_raw, r_env, done, info = env.step(a_idx)
            total_r_env += float(r_env)

            # æ›´æ–° obs / facts
            obs_vec = to_obs_vector(next_obs_raw)
            facts = next_obs_raw.get("facts", {}) if isinstance(next_obs_raw, dict) else {}

            # KB è®°å½•å†å²ï¼ˆå¯é€‰ï¼‰
            if use_cskg and kb is not None and hasattr(kb, "step_update"):
                try:
                    kb.step_update(facts, a_name, float(r_env))
                except Exception:
                    pass

        ep_rewards.append(total_r_env)
        ep_steps.append(step_count)

    # æ±‡æ€»ç»“æœ
    ep_rewards = np.array(ep_rewards, dtype=np.float32)
    ep_steps = np.array(ep_steps, dtype=np.float32)

    summary = {
        "episodes": episodes,
        "mean_env_reward": float(ep_rewards.mean()),
        "std_env_reward": float(ep_rewards.std()),
        "mean_steps": float(ep_steps.mean()),
        "action_counter": action_counter,
    }
    return summary


def print_summary(label: str, summary: Dict[str, Any], top_k: int = 20):
    print(f"\n===== [{label}] è¯„ä¼°ç»“æœ =====")
    print(f"  å›åˆæ•°       : {summary['episodes']}")
    print(
        f"  å¹³å‡ EnvReward: {summary['mean_env_reward']:.3f} Â± {summary['std_env_reward']:.3f}"
    )
    print(f"  å¹³å‡æ­¥é•¿      : {summary['mean_steps']:.1f}")
    print("\n  åŠ¨ä½œä½¿ç”¨ç»Ÿè®¡ï¼ˆTop {}ï¼‰".format(top_k))

    counter: Counter = summary["action_counter"]
    for name, cnt in counter.most_common(top_k):
        print(f"  {name:20s}: {cnt}")


def main():
    parser = argparse.ArgumentParser(
        description="å¯¹æ¯”è¯„ä¼°å¤šä¸ª PPO+CSKG checkpointï¼ˆCSKG on/offï¼‰"
    )
    parser.add_argument(
        "--ckpt",
        nargs="+",
        required=True,
        help="ä¸€ä¸ªæˆ–å¤šä¸ª ckpt è·¯å¾„ï¼Œä¾‹å¦‚ ac_upd025.pt ac_upd100.pt ac_upd200.pt",
    )
    parser.add_argument(
        "--episodes",
        type=int,
        default=20,
        help="æ¯ä¸ªé…ç½®è¯„ä¼°çš„å›åˆæ•°ï¼ˆé»˜è®¤20ï¼‰",
    )
    parser.add_argument(
        "--no-plain",
        action="store_true",
        help="åªè¯„ä¼°å¸¦ CSKGï¼Œä¸è·‘ plain_no_cskg æ¨¡å¼",
    )
    parser.add_argument(
        "--no-cskg",
        action="store_true",
        help="åªè¯„ä¼° plain_no_cskgï¼Œä¸è·‘å¸¦ CSKG æ¨¡å¼",
    )
    args = parser.parse_args()

    cfg = load_ppo_config()
    rule_coef = float(cfg.get("rule_coef", 0.1))

    # è®¾å¤‡è®¾ç½®
    dev_cfg = str(cfg.get("device", "cuda")).lower()
    global DEVICE
    if dev_cfg == "cuda" and torch.cuda.is_available():
        DEVICE = torch.device("cuda")
    else:
        DEVICE = torch.device("cpu")
    print(f"ğŸ“Ÿ ä½¿ç”¨è®¾å¤‡: {DEVICE}, rule_coef={rule_coef}")

    # å»ºä¸€ä¸ª env å¤ç”¨ï¼ˆæ³¨æ„ï¼šçº¢æ–¹åœ¨ reset æ—¶ä»ç„¶ä¼šé‡å»ºï¼‰
    env = build_env()

    # ç”¨äºæœ€åæ•´ä½“æ±‡æ€»
    all_results = []  # æ¯ä¸€è¡Œï¼š{"ckpt", "mode", "mean_reward", "std_reward", "mean_steps"}

    for ckpt_path in args.ckpt:
        ckpt_path = os.path.abspath(ckpt_path)
        if not os.path.exists(ckpt_path):
            print(f"\nâŒ ckpt ä¸å­˜åœ¨: {ckpt_path}")
            continue

        tag = pathlib.Path(ckpt_path).stem  # æ¯”å¦‚ ac_upd025
        print(f"\n==============================")
        print(f"ğŸ” è¯„ä¼°æ¨¡å‹: {ckpt_path}")
        print(f"==============================")

        ac = load_actor_critic(env, ckpt_path)

        # 1) å¸¦ CSKG
        if not args.no_cskg:
            summary_cskg = run_episodes(
                env, ac, episodes=args.episodes, use_cskg=True, rule_coef=rule_coef
            )
            print_summary(f"{tag} + CSKG", summary_cskg)

            all_results.append({
                "ckpt": tag,
                "mode": "cskg",
                "mean_reward": summary_cskg["mean_env_reward"],
                "std_reward": summary_cskg["std_env_reward"],
                "mean_steps": summary_cskg["mean_steps"],
            })

        # 2) å…³é—­ CSKGï¼ˆåªä¿ç•™ env.legal_maskï¼‰
        if not args.no_plain:
            summary_plain = run_episodes(
                env, ac, episodes=args.episodes, use_cskg=False, rule_coef=0.0
            )
            print_summary(f"{tag} plain_no_cskg", summary_plain)

            all_results.append({
                "ckpt": tag,
                "mode": "plain",
                "mean_reward": summary_plain["mean_env_reward"],
                "std_reward": summary_plain["std_env_reward"],
                "mean_steps": summary_plain["mean_steps"],
            })

    env.close()

    # ===== æœ€ç»ˆæ±‡æ€»æ‰“å° =====
    if all_results:
        print("\n\n================ æ€»ä½“å¯¹æ¯”æ±‡æ€» ================")
        # æŒ‰ ckpt + mode æ’ä¸€ä¸‹ï¼Œæ–¹ä¾¿çœ‹
        all_results.sort(key=lambda x: (x["ckpt"], x["mode"]))

        # ç»ˆç«¯è¡¨æ ¼æ‰“å°
        header = f"{'ckpt':15s} {'mode':8s} {'mean_R':>10s} {'std_R':>10s} {'mean_steps':>12s}"
        print(header)
        print("-" * len(header))
        for r in all_results:
            print(
                f"{r['ckpt']:15s} "
                f"{r['mode']:8s} "
                f"{r['mean_reward']:10.3f} "
                f"{r['std_reward']:10.3f} "
                f"{r['mean_steps']:12.2f}"
            )

        # ===== å¯¼å‡º CSV =====
        out_dir = ROOT / "scripts" / "runs" / "ppo_cskg"
        out_dir.mkdir(parents=True, exist_ok=True)
        out_csv = out_dir / f"eval_compare_{int(time.time())}.csv"

        with open(out_csv, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["ckpt", "mode", "mean_reward", "std_reward", "mean_steps"])
            for r in all_results:
                writer.writerow([
                    r["ckpt"],
                    r["mode"],
                    f"{r['mean_reward']:.6f}",
                    f"{r['std_reward']:.6f}",
                    f"{r['mean_steps']:.6f}",
                ])

        print(f"\nğŸ“„ å·²å°†æ±‡æ€»ç»“æœå†™å…¥: {out_csv}")

    print("\nâœ… å¯¹æ¯”è¯„ä¼°å®Œæˆ")


if __name__ == "__main__":
    main()
